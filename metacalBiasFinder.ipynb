{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec2d446f-677d-4fe5-ace5-776239f5faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ngmix\n",
    "import matplotlib.pyplot as plt\n",
    "import galsim\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "\n",
    "def biasFunc(x, m, c):\n",
    "    '''Systematic bias of shear estimation\n",
    "    Parameters:\n",
    "    ----\n",
    "    x:  input shear\n",
    "    m:  multiplicative bias\n",
    "    c:  additive bias\n",
    "\n",
    "    Returns:\n",
    "    ----\n",
    "    y:  estimated shear\n",
    "    '''\n",
    "    y   =   (1+m) * x + c\n",
    "    return y\n",
    "\n",
    "def select(data, shear_type):\n",
    "    \"\"\"\n",
    "    select the data by shear type and size\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: array\n",
    "        The array with fields shear_type and T\n",
    "    shear_type: str\n",
    "        e.g. 'noshear', '1p', etc.\n",
    "    Returns\n",
    "    -------\n",
    "    array of indices\n",
    "    \"\"\"\n",
    "\n",
    "    w, = np.where(\n",
    "        (data['flags'] == 0) & (data['shear_type'] == shear_type)\n",
    "    )\n",
    "    return w\n",
    "\n",
    "def make_struct(res, obs, shear_type):\n",
    "    \"\"\"\n",
    "    make the data structure\n",
    "    Parameters\n",
    "    ----------\n",
    "    res: dict\n",
    "        With keys 's2n', 'e', and 'T'\n",
    "    obs: ngmix.Observation\n",
    "        The observation for this shear type\n",
    "    shear_type: str\n",
    "        The shear type\n",
    "    Returns\n",
    "    -------\n",
    "    1-element array with fields\n",
    "    \"\"\"\n",
    "    dt = [\n",
    "        ('flags', 'i4'),\n",
    "        ('shear_type', 'U7'),\n",
    "        ('s2n', 'f8'),\n",
    "        ('g', 'f8', 2),\n",
    "        ('T', 'f8'),\n",
    "        ('Tpsf', 'f8'),\n",
    "    ]\n",
    "    data = np.zeros(1, dtype=dt)\n",
    "    data['shear_type'] = shear_type\n",
    "    data['flags'] = res['flags']\n",
    "    if res['flags'] == 0:\n",
    "        #data['s2n'] = res['s2n']\n",
    "        data['s2n'] = res['s2n']\n",
    "        # for moments we are actually measureing e, the elliptity\n",
    "        data['g'] = res['e']\n",
    "        data['T'] = res['T']\n",
    "    else:\n",
    "        data['s2n'] = np.nan\n",
    "        data['g'] = np.nan\n",
    "        data['T'] = np.nan\n",
    "        data['Tpsf'] = np.nan\n",
    "\n",
    "        # we only have one epoch and band, so we can get the psf T from the\n",
    "        # observation rather than averaging over epochs/bands\n",
    "        data['Tpsf'] = obs.psf.meta['result']['T']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e93fd6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(rng, FbyB, shear, version=0, first=False, SbyN=20):\n",
    "    \"\"\"\n",
    "    simulate an exponential object with moffat psf\n",
    "    Parameters\n",
    "    ----------\n",
    "    rng: np.random.RandomState\n",
    "        The random number generator\n",
    "    noise: float\n",
    "        Noise for the image\n",
    "    FbyB: float\n",
    "        source by background ratio\n",
    "    shear: (g1, g2)\n",
    "        The shear in each component\n",
    "    Returns\n",
    "    -------\n",
    "    ngmix.Observation\n",
    "    \"\"\"\n",
    "\n",
    "    scale    = 0.263\n",
    "    psf_fwhm = 0.9\n",
    "    gal_hlr  = 0.5\n",
    "    dy, dx   = rng.uniform(low=-scale/2, high=scale/2, size=2)\n",
    "\n",
    "    psf = galsim.Moffat(beta=2.5, fwhm=psf_fwhm,\n",
    "    ).shear(g1=0.02, g2=-0.01,)\n",
    "    \n",
    "    \n",
    "    obj0 = galsim.Exponential(\n",
    "        half_light_radius=gal_hlr, flux=125e3\n",
    "    ).shear(\n",
    "        g1=shear,\n",
    "        g2=0,\n",
    "    ).shift(dx=dx, dy=dy,)\n",
    "    obj = galsim.Convolve(psf, obj0)\n",
    "\n",
    "    psf_im = psf.drawImage(scale=scale).array\n",
    "    im = obj.drawImage(scale = scale)\n",
    " \n",
    "    # psf noise\n",
    "    psf_noise= 1e-9\n",
    "    psf_im += rng.normal(scale=psf_noise, size=psf_im.shape)\n",
    "    \n",
    "    ngrid = im.array.shape[0]\n",
    "    flux_tmp = np.sum((im.array)[ngrid//2-2:ngrid//2+3, ngrid//2-2:ngrid//2+3])\n",
    "    std_tmp =  5\n",
    "    F = SbyN**2.*(1+FbyB)/FbyB\n",
    "    B = F/FbyB\n",
    "    B_val = B/25.0\n",
    "    F_val=F/25.0\n",
    "        \n",
    "    im = (im/flux_tmp)*F\n",
    "    \n",
    "    \n",
    "    if version==0:\n",
    "        noise_image = rng.normal(scale=1, size=im.array.shape)\n",
    "        noise_image *= np.sqrt(B_val + im.array)/std_tmp\n",
    "        variance_array = np.ones_like(im.array)*(B_val+im.array)/std_tmp**2\n",
    "        im += noise_image\n",
    "            \n",
    "    if version==1:\n",
    "        noise_image = rng.normal(scale=1, size=im.array.shape)\n",
    "        noise_image *= np.sqrt(B_val+F_val)/std_tmp\n",
    "        variance_array = np.ones_like(im.array)*(B_val+F_val)/std_tmp**2\n",
    "        im += noise_image\n",
    "\n",
    "        \n",
    "    imArr = im.array\n",
    "    \n",
    "    cen = (np.array(imArr.shape)-1.0)/2.0\n",
    "    psf_cen = (np.array(psf_im.shape)-1.0)/2.0\n",
    "    jacobian = ngmix.DiagonalJacobian(\n",
    "        row=cen[0] + dy/scale, col=cen[1] + dx/scale, scale=scale,\n",
    "    )\n",
    "    psf_jacobian = ngmix.DiagonalJacobian(\n",
    "        row=psf_cen[0], col=psf_cen[1], scale=scale,\n",
    "    )\n",
    "\n",
    "    # noise variance map\n",
    "    if version==0:\n",
    "        wt = 1.0/np.average(variance_array)*np.ones_like(variance_array)\n",
    "    if version==1:\n",
    "        wt = 1.0/variance_array\n",
    "        \n",
    "    psf_wt = psf_im*0 + 1.0/psf_noise**2\n",
    "\n",
    "    psf_obs = ngmix.Observation(\n",
    "        psf_im,\n",
    "        weight=psf_wt,\n",
    "        jacobian=psf_jacobian,\n",
    "    )\n",
    "    obs = ngmix.Observation(\n",
    "        imArr,\n",
    "        weight=wt,\n",
    "        jacobian=jacobian,\n",
    "        psf=psf_obs,\n",
    "    )\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3da0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(rng, num_tests, num_gals, FBratioArr, shear_true, version=0, first=False, SbyN=20):\n",
    "    data = []\n",
    "    x = []\n",
    "    y = []\n",
    "    shear_error = []\n",
    "    \n",
    "    for i in range(num_tests):\n",
    "        print(\"len(data[]) =\", len(data))\n",
    "        dlist = []\n",
    "        \n",
    "        for j in range(num_gals):\n",
    "            imgdata = make_data(rng=rng, FbyB=FBratioArr[i], shear=shear_true[i], version=version, first=first, SbyN=20)\n",
    "            obs = imgdata\n",
    "\n",
    "            resdict, obsdict = boot.go(obs)\n",
    "            for stype, sres in resdict.items():\n",
    "                st = make_struct(res=sres, obs=obsdict[stype], shear_type=stype)\n",
    "                dlist.append(st)\n",
    "\n",
    "        data.append(np.hstack(dlist))\n",
    "        #data contains average of all galaxy data\n",
    "\n",
    "        w = select(data=data[i], shear_type='noshear')\n",
    "        w_1p = select(data=data[i], shear_type='1p')\n",
    "        w_1m = select(data=data[i], shear_type='1m')\n",
    "        g_1p = data[i]['g'][w_1p, 0].mean()\n",
    "        g_1m = data[i]['g'][w_1m, 0].mean()\n",
    "        R11 = (g_1p - g_1m)/0.02\n",
    "\n",
    "        g = data[i]['g'][w].mean(axis=0)\n",
    "        shear = g / R11\n",
    "\n",
    "        g_error = data[i]['g'][w].std(axis=0) / np.sqrt(w.size)\n",
    "        shear_error.append(g_error[0]/R11)\n",
    "\n",
    "        x.append(FBratioArr[i])\n",
    "        y.append(shear[0])\n",
    "\n",
    "            \n",
    "    return (x, y, shear_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a911faf6-8e07-4c3a-abdc-b73bf9617aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1024)\n",
    "#rng = galsim.BaseDeviate(1024)\n",
    "\n",
    "# We will measure moments with a fixed gaussian weight function\n",
    "weight_fwhm= 1.2\n",
    "fitter     = ngmix.gaussmom.GaussMom(fwhm=weight_fwhm)\n",
    "psf_fitter = ngmix.gaussmom.GaussMom(fwhm=weight_fwhm)\n",
    "\n",
    "# these \"runners\" run the measurement code on observations\n",
    "psf_runner = ngmix.runners.PSFRunner(fitter=psf_fitter)\n",
    "runner     = ngmix.runners.Runner(fitter=fitter)\n",
    "\n",
    "# this \"bootstrapper\" runs the metacal image shearing as well as both psf\n",
    "# and object measurements\n",
    "#\n",
    "# We will just do R11 for simplicity and to speed up this example;\n",
    "# typically the off diagonal terms are negligible, and R11 and R22 are\n",
    "# usually consistent\n",
    "boot      = ngmix.metacal.MetacalBootstrapper(\n",
    "    runner= runner, psf_runner=psf_runner,\n",
    "    rng=rng,\n",
    "    psf='gauss',\n",
    "    types=['noshear', '1p', '1m'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c11d0519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data[]) = 0\n",
      "len(data[]) = 1\n",
      "len(data[]) = 2\n",
      "len(data[]) = 3\n",
      "len(data[]) = 4\n",
      "len(data[]) = 0\n",
      "len(data[]) = 1\n",
      "len(data[]) = 2\n",
      "len(data[]) = 3\n",
      "len(data[]) = 4\n",
      "len(data[]) = 0\n",
      "len(data[]) = 1\n",
      "len(data[]) = 2\n",
      "len(data[]) = 3\n",
      "len(data[]) = 4\n",
      "len(data[]) = 0\n",
      "len(data[]) = 1\n",
      "len(data[]) = 2\n",
      "len(data[]) = 3\n",
      "len(data[]) = 4\n"
     ]
    }
   ],
   "source": [
    "FBratioArr = np.logspace(start=-2, stop=2, num=5, base=10.0)\n",
    "num_tests = len(FBratioArr)\n",
    "num_gals = 100\n",
    "g_true= [-0.03, -0.01, 0, 0.01, 0.03]\n",
    "\n",
    "analysis_BandS1 = analyze(rng, num_tests, num_gals, FBratioArr, g_true, version=0, first = True, SbyN=20)\n",
    "analysis_BandS2 = analyze(rng, num_tests, num_gals, FBratioArr, g_true, version=0, first = True, SbyN=20)\n",
    "\n",
    "analysis_Bonly1 = analyze(rng, num_tests, num_gals, FBratioArr, g_true, version=1, first = True, SbyN=20)\n",
    "analysis_Bonly2 = analyze(rng, num_tests, num_gals, FBratioArr, g_true, version=1, first = True, SbyN=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d99ef034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_true[n] = -0.03\n",
      "tempBiasV0 =  [-0.03226904112005742, -0.025103348666702593]\n",
      "tempBiasErrorsV0 =  [0.0031974252826337214, 0.0028273459193107887]\n",
      "poptV0 =  [-6008.34297234  -180.24853695]\n",
      "tempBiasV1 =  [-0.030157989063746036, -0.031959299645932776]\n",
      "tempBiasErrorsV1 =  [0.0032111764575349804, 0.0029966472834220825]\n",
      "poptV1 =  [6548.33657457  196.44897647]\n",
      "\n",
      "\n",
      "g_true[n] = -0.01\n",
      "tempBiasV0 =  [-0.010141526050268143, -0.008574848353411877]\n",
      "tempBiasErrorsV0 =  [0.0029238947165782228, 0.0031089624788839705]\n",
      "poptV0 =  [51533.08579691   515.33145179]\n",
      "tempBiasV1 =  [-0.008140369636702722, -0.007986874656557568]\n",
      "tempBiasErrorsV1 =  [0.0031287385701920223, 0.003097712155051114]\n",
      "poptV1 =  [88226.44030164   882.26634016]\n",
      "\n",
      "\n",
      "g_true[n] = 0\n",
      "tempBiasV0 =  [0.0015218353345612947, 0.0012630488142850854]\n",
      "tempBiasErrorsV0 =  [0.0023191330122909128, 0.002686198538804608]\n",
      "poptV0 =  [1.         0.00141132]\n",
      "tempBiasV1 =  [-0.000973257719325112, 0.004792399061257314]\n",
      "tempBiasErrorsV1 =  [0.003027086938637535, 0.0027274182392038257]\n",
      "poptV1 =  [1.         0.00220901]\n",
      "\n",
      "\n",
      "g_true[n] = 0.01\n",
      "tempBiasV0 =  [0.0077124309228725095, 0.010628836989754996]\n",
      "tempBiasErrorsV0 =  [0.002127791796015172, 0.0021662084306538474]\n",
      "poptV0 =  [-37810.01585889    378.09930301]\n",
      "tempBiasV1 =  [0.014302583097299641, 0.01212361361667861]\n",
      "tempBiasErrorsV1 =  [0.003102444634910163, 0.0028154133369455293]\n",
      "poptV1 =  [-14331.64698631    143.31957761]\n",
      "\n",
      "\n",
      "g_true[n] = 0.03\n",
      "tempBiasV0 =  [0.030971311793426347, 0.029427558633171653]\n",
      "tempBiasErrorsV0 =  [0.0017059514779314143, 0.0017161036990622036]\n",
      "poptV0 =  [-487.85480722   14.6358482 ]\n",
      "tempBiasV1 =  [0.032837772145763194, 0.036176916695386946]\n",
      "tempBiasErrorsV1 =  [0.0031874246586436595, 0.002793470334504109]\n",
      "poptV1 =  [6486.01310623 -194.57566682]\n",
      "\n",
      "\n",
      "biasList = [array([-487.85480722,   14.6358482 ]), array([6486.01310623, -194.57566682])]\n",
      "errorList = [array([[inf, inf],\n",
      "       [inf, inf]]), array([[inf, inf],\n",
      "       [inf, inf]])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(20, 10))\\nplt.errorbar(np.array(g_true)*1.1, g1_est, yerr=g2_sigma, fmt=\\'o\\', label=\\'Background + Source\\')\\nplt.errorbar(g_true, g2_est, yerr=g2_sigma, fmt=\\'o\\', label=\\'Background only\\')\\n#plt.plot(x, y, color=\"purple\")\\nplt.plot(np.array(x), biasFunc(np.array(x), poptV0[0], poptV0[1]), label = \\'Background + Source\\', color = \"blue\")\\nplt.plot(np.array(x), biasFunc(np.array(x), poptV1[0], poptV1[1]), label = \\'Background only\\', color = \"orange\")\\nplt.axhline(0, color=\"purple\")\\nplt.axvline(0, color=\"purple\")\\nplt.xlabel(r\\'$g_{true}$\\', fontsize=16)\\nplt.ylabel(r\\'$g_{est}$\\', fontsize=16)\\nplt.legend()\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#popt, pcov = scipy.optimize.curve_fit(biasFunc, shear_true[0], shear[0], sigma = shear_error[0])\n",
    "\n",
    "x = np.linspace(-.03*1.5, .03*1.5, len(FBratioArr))\n",
    "\n",
    "FbyBlist = analysis_BandS1[0]\n",
    "\n",
    "\"\"\"\n",
    "print(\"analysis_BandS1\", analysis_BandS1[1])\n",
    "print(\"analysis_BandS2\", analysis_BandS2[1])\n",
    "print(\"analysis_Bonly1\", analysis_Bonly1[1])\n",
    "print(\"analysis_Bonly2\", analysis_Bonly2[1])\n",
    "\"\"\"\n",
    "\n",
    "g11_est = analysis_BandS1[1]\n",
    "g11_sigma = analysis_BandS1[2]\n",
    "\n",
    "g12_est = analysis_BandS2[1]\n",
    "g12_sigma = analysis_BandS2[2]\n",
    "\n",
    "g21_est = analysis_Bonly1[1]\n",
    "g21_sigma = analysis_Bonly1[2]\n",
    "\n",
    "g22_est = analysis_Bonly2[1]\n",
    "g22_sigma = analysis_Bonly2[2]\n",
    "\n",
    "\"\"\"\n",
    "print(\"g11_est =\", g11_est)\n",
    "print(\"g12_est =\", g12_est)\n",
    "\n",
    "print(\"g21_est =\", g21_est)\n",
    "print(\"g22_est =\", g22_est)\n",
    "\n",
    "print(\"g_true =\", g_true)\n",
    "\n",
    "print(\"g11_sigma =\", g11_sigma)\n",
    "print(\"g12_sigma =\", g12_sigma)\n",
    "\n",
    "print(\"g21_sigma =\", g21_sigma)\n",
    "print(\"g22_sigma =\", g22_sigma)\n",
    "\"\"\"\n",
    "\n",
    "for n in range(len(g_true)):\n",
    "    tempBiasV0 = []\n",
    "    tempBiasV1 = []\n",
    "    tempBiasErrorsV0 = []\n",
    "    tempBiasErrorsV1 = []\n",
    "    biasList = []\n",
    "    errorList = []\n",
    "    \n",
    "    tempBiasV0.append(g11_est[n])\n",
    "    tempBiasV0.append(g12_est[n])\n",
    "    \n",
    "    tempBiasV1.append(g21_est[n])\n",
    "    tempBiasV1.append(g22_est[n])\n",
    "    \n",
    "    tempBiasErrorsV0.append(g11_sigma[n])\n",
    "    tempBiasErrorsV0.append(g12_sigma[n])\n",
    "    \n",
    "    tempBiasErrorsV1.append(g21_sigma[n])\n",
    "    tempBiasErrorsV1.append(g22_sigma[n])\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"shape(tempBiasV0)\", np.shape(tempBiasV0))\n",
    "    print(\"shape(tempBiasV1)\", np.shape(tempBiasV1))\n",
    "    print(\"shape(tempBiasErrorsV0)\", np.shape(tempBiasErrorsV0))\n",
    "    print(\"shape(tempBiasErrorsV1)\", np.shape(tempBiasErrorsV1))\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"g_true[n] =\", g_true[n])\n",
    "    poptV0, pcovV0 = scipy.optimize.curve_fit(biasFunc, g_true[n], tempBiasV0, sigma = tempBiasErrorsV0)\n",
    "    print(\"tempBiasV0 = \",tempBiasV0)\n",
    "    print(\"tempBiasErrorsV0 = \",tempBiasErrorsV0)\n",
    "    print(\"poptV0 = \",poptV0)\n",
    "    poptV1, pcovV1 = scipy.optimize.curve_fit(biasFunc, g_true[n], tempBiasV1, sigma = tempBiasErrorsV1)\n",
    "    print(\"tempBiasV1 = \",tempBiasV1)\n",
    "    print(\"tempBiasErrorsV1 = \",tempBiasErrorsV1)\n",
    "    print(\"poptV1 = \",poptV1)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    biasList.append(poptV0)\n",
    "    biasList.append(poptV1)\n",
    "    \n",
    "    errorList.append(pcovV0)\n",
    "    errorList.append(pcovV1)\n",
    "\n",
    "print(\"biasList =\", biasList)\n",
    "print(\"errorList =\", errorList)\n",
    "\n",
    "\"\"\"\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.errorbar(np.array(g_true)*1.1, g1_est, yerr=g2_sigma, fmt='o', label='Background + Source')\n",
    "plt.errorbar(g_true, g2_est, yerr=g2_sigma, fmt='o', label='Background only')\n",
    "#plt.plot(x, y, color=\"purple\")\n",
    "plt.plot(np.array(x), biasFunc(np.array(x), poptV0[0], poptV0[1]), label = 'Background + Source', color = \"blue\")\n",
    "plt.plot(np.array(x), biasFunc(np.array(x), poptV1[0], poptV1[1]), label = 'Background only', color = \"orange\")\n",
    "plt.axhline(0, color=\"purple\")\n",
    "plt.axvline(0, color=\"purple\")\n",
    "plt.xlabel(r'$g_{true}$', fontsize=16)\n",
    "plt.ylabel(r'$g_{est}$', fontsize=16)\n",
    "plt.legend()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab76da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (p1, p2) = plt.subplots(2, figsize=(5,25))\n",
    "\n",
    "print(np.shape(FbyBlist))\n",
    "print(biasVals0)\n",
    "\n",
    "plot1 = p1.errorbar(np.array(FbyBlist)*1.1, biasVals0[0], np.sqrt(np.diag(biasError0)), fmt='o', label='Background + Source')\n",
    "p1.errorbar(FbyBlist, biasVals1[0], np.average(biasError1[0]), fmt='o', label='Background only')\n",
    "p1.set_title(\"Multiplicative Bias Plot\")\n",
    "p1.axhline(0, color=\"purple\")\n",
    "p1.xlabel(r'$\\frac{F}{B}$', fontsize=16)\n",
    "p1.ylabel(r'$m$', fontsize=16)\n",
    "p1.xscale(\"log\")\n",
    "\n",
    "\n",
    "plot2 = p2.errorbar(np.array(FbyBlist)*1.1, biasVals0[1], np.average(biasError0[1]), fmt='o', label='Background + Source')\n",
    "p2.errorbar(FbyBlist, biasVals1[1], np.average(biasError1[1]), fmt = 'o', label ='Background only')\n",
    "p2.axhline(0, color=\"purple\")\n",
    "p2.xlabel(r'$\\frac{F}{B}$', fontsize=16)\n",
    "p2.ylabel(r'$c$', fontsize=16)\n",
    "p2.xscale(\"log\")\n",
    "p2.set_title(\"Additive Bias Plot\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b655cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
