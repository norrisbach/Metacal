{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec2d446f-677d-4fe5-ace5-776239f5faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ngmix\n",
    "import matplotlib.pyplot as plt\n",
    "import galsim\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "from schwimmbad import MPIPool\n",
    "\n",
    "def biasFunc(x, m, c):\n",
    "    '''Systematic bias of shear estimation\n",
    "    Parameters:\n",
    "    ----\n",
    "    x:  input shear\n",
    "    m:  multiplicative bias\n",
    "    c:  additive bias\n",
    "\n",
    "    Returns:\n",
    "    ----\n",
    "    y:  estimated shear\n",
    "    '''\n",
    "    y   =   (1+m) * x + c\n",
    "    return y\n",
    "\n",
    "def select(data, shear_type):\n",
    "    \"\"\"\n",
    "    select the data by shear type and size\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: array\n",
    "        The array with fields shear_type and T\n",
    "    shear_type: str\n",
    "        e.g. 'noshear', '1p', etc.\n",
    "    Returns\n",
    "    -------\n",
    "    array of indices\n",
    "    \"\"\"\n",
    "\n",
    "    w, = np.where(\n",
    "        (data['flags'] == 0) & (data['shear_type'] == shear_type)\n",
    "    )\n",
    "    return w\n",
    "\n",
    "def make_struct(res, obs, shear_type):\n",
    "    \"\"\"\n",
    "    make the data structure\n",
    "    Parameters\n",
    "    ----------\n",
    "    res: dict\n",
    "        With keys 's2n', 'e', and 'T'\n",
    "    obs: ngmix.Observation\n",
    "        The observation for this shear type\n",
    "    shear_type: str\n",
    "        The shear type\n",
    "    Returns\n",
    "    -------\n",
    "    1-element array with fields\n",
    "    \"\"\"\n",
    "    dt = [\n",
    "        ('flags', 'i4'),\n",
    "        ('shear_type', 'U7'),\n",
    "        ('s2n', 'f8'),\n",
    "        ('g', 'f8', 2),\n",
    "        ('T', 'f8'),\n",
    "        ('Tpsf', 'f8'),\n",
    "    ]\n",
    "    data = np.zeros(1, dtype=dt)\n",
    "    data['shear_type'] = shear_type\n",
    "    data['flags'] = res['flags']\n",
    "    if res['flags'] == 0:\n",
    "        #data['s2n'] = res['s2n']\n",
    "        data['s2n'] = res['s2n']\n",
    "        # for moments we are actually measureing e, the elliptity\n",
    "        data['g'] = res['e']\n",
    "        data['T'] = res['T']\n",
    "    else:\n",
    "        data['s2n'] = np.nan\n",
    "        data['g'] = np.nan\n",
    "        data['T'] = np.nan\n",
    "        data['Tpsf'] = np.nan\n",
    "\n",
    "        # we only have one epoch and band, so we can get the psf T from the\n",
    "        # observation rather than averaging over epochs/bands\n",
    "        data['Tpsf'] = obs.psf.meta['result']['T']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e93fd6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(rng, FbyB, shear, version=0, SbyN=20):\n",
    "    \"\"\"\n",
    "    simulate an exponential object with moffat psf\n",
    "    Parameters\n",
    "    ----------\n",
    "    rng: np.random.RandomState\n",
    "        The random number generator\n",
    "    noise: float\n",
    "        Noise for the image\n",
    "    FbyB: float\n",
    "        source by background ratio\n",
    "    shear: (g1, g2)\n",
    "        The shear in each component\n",
    "    Returns\n",
    "    -------\n",
    "    ngmix.Observation\n",
    "    \"\"\"\n",
    "\n",
    "    scale    = 0.263\n",
    "    psf_fwhm = 0.9\n",
    "    gal_hlr  = 0.5\n",
    "    dy, dx   = rng.uniform(low=-scale/2, high=scale/2, size=2)\n",
    "\n",
    "    psf = galsim.Moffat(beta=2.5, fwhm=psf_fwhm,\n",
    "    ).shear(g1=0.02, g2=-0.01,)\n",
    "    \n",
    "    \n",
    "    obj0 = galsim.Exponential(\n",
    "        half_light_radius=gal_hlr, flux=125e3\n",
    "    ).shear(\n",
    "        g1=shear,\n",
    "        g2=0,\n",
    "    ).shift(dx=dx, dy=dy,)\n",
    "    obj = galsim.Convolve(psf, obj0)\n",
    "\n",
    "    psf_im = psf.drawImage(scale=scale).array\n",
    "    im = obj.drawImage(scale = scale)\n",
    " \n",
    "    # psf noise\n",
    "    psf_noise= 1e-9\n",
    "    psf_im += rng.normal(scale=psf_noise, size=psf_im.shape)\n",
    "    radius = 10\n",
    "    \n",
    "    ngrid = im.array.shape[0]\n",
    "    flux_tmp = np.sum((im.array)[ngrid//2-radius:ngrid//2+radius+1, ngrid//2-radius:ngrid//2+radius+1])\n",
    "    F = SbyN**2.*(1+FbyB)/FbyB\n",
    "    B = F/FbyB\n",
    "    B_val = B/(2.*radius+1)**2.\n",
    "    F_val= F/(2.*radius+1)**2.\n",
    "        \n",
    "    im = (im/flux_tmp)*F\n",
    "    \n",
    "    \n",
    "    if version==0:\n",
    "        noise_image = rng.normal(scale=1, size=im.array.shape)\n",
    "        noise_image *= np.sqrt(B_val + im.array)\n",
    "            \n",
    "    if version==1:\n",
    "        noise_image = rng.normal(scale=1, size=im.array.shape)\n",
    "        noise_image *= np.sqrt(B_val+F_val)\n",
    "\n",
    "    variance_array = np.ones_like(im.array)*(B_val+F_val)\n",
    "    im += noise_image\n",
    "    wt = 1.0/variance_array\n",
    "    imArr = im.array\n",
    "    \n",
    "    cen = (np.array(imArr.shape)-1.0)/2.0\n",
    "    psf_cen = (np.array(psf_im.shape)-1.0)/2.0\n",
    "    jacobian = ngmix.DiagonalJacobian(\n",
    "        row=cen[0] + dy/scale, col=cen[1] + dx/scale, scale=scale,\n",
    "    )\n",
    "    psf_jacobian = ngmix.DiagonalJacobian(\n",
    "        row=psf_cen[0], col=psf_cen[1], scale=scale,\n",
    "    )\n",
    "        \n",
    "    psf_wt = psf_im*0 + 1.0/psf_noise**2\n",
    "\n",
    "    psf_obs = ngmix.Observation(\n",
    "        psf_im,\n",
    "        weight=psf_wt,\n",
    "        jacobian=psf_jacobian,\n",
    "    )\n",
    "    obs = ngmix.Observation(\n",
    "        imArr,\n",
    "        weight=wt,\n",
    "        jacobian=jacobian,\n",
    "        psf=psf_obs,\n",
    "    )\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3da0585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nanalyze(num_gals, FbyB, shear_true, seedArr, version=0, first=False, SbyN=20):\\n    info\\n    if ~version:\\n        print('Analyzing for F/B= %.2f' %FbyB)\\n    else:\\n        print('Analyzing for F/B= 0')\\n    data = []\\n    x = []\\n    y = []\\n    s2nArr=[]\\n    shear_error = []\\n    \\n    for i in range(len(shear_true)):\\n        seedNum = seedArr[i]\\n        rng = np.random.RandomState(seedNum)\\n        shearIn = shear_true[i]\\n        print('Analyzing for shear= %.2f' %shearIn)\\n        \\n        dlist = []\\n        \\n        for j in range(num_gals):\\n            imgdata = make_data(rng=rng, FbyB=FbyB, shear=shearIn, version=version, SbyN=SbyN)\\n            obs = imgdata\\n\\n            resdict, obsdict = boot.go(obs)\\n            for stype, sres in resdict.items():\\n                st = make_struct(res=sres, obs=obsdict[stype], shear_type=stype)\\n                dlist.append(st)\\n                del st\\n            del obs, resdict, obsdict\\n\\n        data = np.hstack(dlist)\\n        del dlist\\n        \\n        w = select(data=data, shear_type='noshear')\\n        w_1p = select(data=data, shear_type='1p')\\n        w_1m = select(data=data, shear_type='1m')\\n        g_1p = data['g'][w_1p, 0].mean()\\n        g_1m = data['g'][w_1m, 0].mean()\\n        R11 = (g_1p - g_1m)/0.02\\n        s2n = data['s2n'].mean()\\n\\n        g = data['g'][w].mean(axis=0)\\n        shear = g / R11\\n\\n        g_error = data['g'][w].std(axis=0) / np.sqrt(w.size)\\n        shear_error.append(g_error[0]/R11)\\n\\n        x.append(FbyB)\\n        y.append(shear[0])\\n        s2nArr.append(s2n)\\n        del data\\n        \\n\\n            \\n    return (x, y, shear_error, s2nArr)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "analyze(num_gals, FbyB, shear_true, seedArr, version=0, first=False, SbyN=20):\n",
    "    info\n",
    "    if ~version:\n",
    "        print('Analyzing for F/B= %.2f' %FbyB)\n",
    "    else:\n",
    "        print('Analyzing for F/B= 0')\n",
    "    data = []\n",
    "    x = []\n",
    "    y = []\n",
    "    s2nArr=[]\n",
    "    shear_error = []\n",
    "    \n",
    "    for i in range(len(shear_true)):\n",
    "        seedNum = seedArr[i]\n",
    "        rng = np.random.RandomState(seedNum)\n",
    "        shearIn = shear_true[i]\n",
    "        print('Analyzing for shear= %.2f' %shearIn)\n",
    "        \n",
    "        dlist = []\n",
    "        \n",
    "        for j in range(num_gals):\n",
    "            imgdata = make_data(rng=rng, FbyB=FbyB, shear=shearIn, version=version, SbyN=SbyN)\n",
    "            obs = imgdata\n",
    "\n",
    "            resdict, obsdict = boot.go(obs)\n",
    "            for stype, sres in resdict.items():\n",
    "                st = make_struct(res=sres, obs=obsdict[stype], shear_type=stype)\n",
    "                dlist.append(st)\n",
    "                del st\n",
    "            del obs, resdict, obsdict\n",
    "\n",
    "        data = np.hstack(dlist)\n",
    "        del dlist\n",
    "        \n",
    "        w = select(data=data, shear_type='noshear')\n",
    "        w_1p = select(data=data, shear_type='1p')\n",
    "        w_1m = select(data=data, shear_type='1m')\n",
    "        g_1p = data['g'][w_1p, 0].mean()\n",
    "        g_1m = data['g'][w_1m, 0].mean()\n",
    "        R11 = (g_1p - g_1m)/0.02\n",
    "        s2n = data['s2n'].mean()\n",
    "\n",
    "        g = data['g'][w].mean(axis=0)\n",
    "        shear = g / R11\n",
    "\n",
    "        g_error = data['g'][w].std(axis=0) / np.sqrt(w.size)\n",
    "        shear_error.append(g_error[0]/R11)\n",
    "\n",
    "        x.append(FbyB)\n",
    "        y.append(shear[0])\n",
    "        s2nArr.append(s2n)\n",
    "        del data\n",
    "        \n",
    "\n",
    "            \n",
    "    return (x, y, shear_error, s2nArr)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2024281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(info):\n",
    "    info\n",
    "    if ~version:\n",
    "        print('Analyzing for F/B= %.2f' %info[1])\n",
    "    else:\n",
    "        print('Analyzing for F/B= 0')\n",
    "    data = []\n",
    "    x = []\n",
    "    y = []\n",
    "    s2nArr=[]\n",
    "    shear_error = []\n",
    "    \n",
    "    for i in range(len(info[2])):\n",
    "        seedNum = info[3][i]\n",
    "        rng = np.random.RandomState(seedNum)\n",
    "        shearIn = info[2][i]\n",
    "        print('Analyzing for shear= %.2f' %shearIn)\n",
    "        \n",
    "        dlist = []\n",
    "        \n",
    "        for j in range(info[0]):\n",
    "            imgdata = make_data(rng=rng, FbyB=info[1], shear=shearIn, version=info[4], SbyN=info[6])\n",
    "            obs = imgdata\n",
    "\n",
    "            resdict, obsdict = boot.go(obs)\n",
    "            for stype, sres in resdict.items():\n",
    "                st = make_struct(res=sres, obs=obsdict[stype], shear_type=stype)\n",
    "                dlist.append(st)\n",
    "                del st\n",
    "            del obs, resdict, obsdict\n",
    "\n",
    "        data = np.hstack(dlist)\n",
    "        del dlist\n",
    "        \n",
    "        w = select(data=data, shear_type='noshear')\n",
    "        w_1p = select(data=data, shear_type='1p')\n",
    "        w_1m = select(data=data, shear_type='1m')\n",
    "        g_1p = data['g'][w_1p, 0].mean()\n",
    "        g_1m = data['g'][w_1m, 0].mean()\n",
    "        R11 = (g_1p - g_1m)/0.02\n",
    "        s2n = data['s2n'].mean()\n",
    "\n",
    "        g = data['g'][w].mean(axis=0)\n",
    "        shear = g / R11\n",
    "\n",
    "        g_error = data['g'][w].std(axis=0) / np.sqrt(w.size)\n",
    "        shear_error.append(g_error[0]/R11)\n",
    "\n",
    "        x.append(info[1])\n",
    "        y.append(shear[0])\n",
    "        s2nArr.append(s2n)\n",
    "        del data\n",
    "        \n",
    "\n",
    "            \n",
    "    return (x, y, shear_error, s2nArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a911faf6-8e07-4c3a-abdc-b73bf9617aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1001)\n",
    "\n",
    "# We will measure moments with a fixed gaussian weight function\n",
    "weight_fwhm= 1.2\n",
    "fitter     = ngmix.gaussmom.GaussMom(fwhm=weight_fwhm)\n",
    "psf_fitter = ngmix.gaussmom.GaussMom(fwhm=weight_fwhm)\n",
    "\n",
    "# these \"runners\" run the measurement code on observations\n",
    "psf_runner = ngmix.runners.PSFRunner(fitter=psf_fitter)\n",
    "runner     = ngmix.runners.Runner(fitter=fitter)\n",
    "\n",
    "# this \"bootstrapper\" runs the metacal image shearing as well as both psf\n",
    "# and object measurements\n",
    "#\n",
    "# We will just do R11 for simplicity and to speed up this example;\n",
    "# typically the off diagonal terms are negligible, and R11 and R22 are\n",
    "# usually consistent\n",
    "boot      = ngmix.metacal.MetacalBootstrapper(\n",
    "    runner= runner, psf_runner=psf_runner,\n",
    "    rng=rng,\n",
    "    psf='gauss',\n",
    "    types=['noshear', '1p', '1m'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a396930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100, 0.01, [-0.03, -0.01, 0, 0.01, 0.03], [1, 2, 3, 4, 5], 0, False, 20), (100, 0.1, [-0.03, -0.01, 0, 0.01, 0.03], [1, 2, 3, 4, 5], 0, False, 20), (100, 1.0, [-0.03, -0.01, 0, 0.01, 0.03], [1, 2, 3, 4, 5], 0, False, 20), (100, 10.0, [-0.03, -0.01, 0, 0.01, 0.03], [1, 2, 3, 4, 5], 0, False, 20), (100, 100.0, [-0.03, -0.01, 0, 0.01, 0.03], [1, 2, 3, 4, 5], 0, False, 20)]\n",
      "Analyzing for F/B= 0.01\n",
      "Analyzing for shear= -0.03\n",
      "Analyzing for shear= -0.01\n",
      "Analyzing for shear= 0.00\n",
      "Analyzing for shear= 0.01\n",
      "Analyzing for shear= 0.03\n",
      "Analyzing for F/B= 0.10\n",
      "Analyzing for shear= -0.03\n",
      "Analyzing for shear= -0.01\n",
      "Analyzing for shear= 0.00\n",
      "Analyzing for shear= 0.01\n",
      "Analyzing for shear= 0.03\n",
      "Analyzing for F/B= 1.00\n",
      "Analyzing for shear= -0.03\n",
      "Analyzing for shear= -0.01\n",
      "Analyzing for shear= 0.00\n",
      "Analyzing for shear= 0.01\n",
      "Analyzing for shear= 0.03\n",
      "Analyzing for F/B= 10.00\n",
      "Analyzing for shear= -0.03\n",
      "Analyzing for shear= -0.01\n",
      "Analyzing for shear= 0.00\n",
      "Analyzing for shear= 0.01\n",
      "Analyzing for shear= 0.03\n",
      "Analyzing for F/B= 100.00\n",
      "Analyzing for shear= -0.03\n",
      "Analyzing for shear= -0.01\n",
      "Analyzing for shear= 0.00\n",
      "Analyzing for shear= 0.01\n",
      "Analyzing for shear= 0.03\n"
     ]
    }
   ],
   "source": [
    "FBratioArr = np.logspace(start=-2, stop=2, num=5, base=10.0)\n",
    "num_gals = 100\n",
    "g_true= [-0.03, -0.01, 0, 0.01, 0.03]\n",
    "seed = [1, 2, 3, 4, 5]\n",
    "version = 0\n",
    "first = False\n",
    "SbyN = 20\n",
    "data=[]\n",
    "\n",
    "for n in range(5):\n",
    "    element = (num_gals, FBratioArr[n], g_true, seed, version, first, SbyN)\n",
    "    data.append(element)\n",
    "print(data)\n",
    "    \n",
    "answer = list(map(analyze, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9f7d57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.01, 0.01, 0.01, 0.01, 0.01], [-0.025594966158756137, -0.02230527278043407, -0.01373388949889737, 0.02209921570142928, 0.033687677083023115], [0.009439230680953143, 0.009640632059566686, 0.009096750073319558, 0.008628468077781903, 0.00924189945756109], [34.468263763601634, 34.4075561267097, 34.55506148570242, 34.53801293318223, 34.221965824420536])\n"
     ]
    }
   ],
   "source": [
    "print(answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78a3d284",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tried to create an MPI pool, but there was only one MPI process available. Need at least two.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     element \u001b[38;5;241m=\u001b[39m (num_gals, FBratioArr[n], g_true[n], seed[n], version, first, SbyN)\n\u001b[1;32m     13\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend(element)\n\u001b[0;32m---> 15\u001b[0m pool \u001b[38;5;241m=\u001b[39m \u001b[43mMPIPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool\u001b[38;5;241m.\u001b[39mis_master():\n\u001b[1;32m     17\u001b[0m     pool\u001b[38;5;241m.\u001b[39mwait()\n",
      "File \u001b[0;32m~/work/ana/miniconda3/envs/mpienv/lib/python3.10/site-packages/schwimmbad/mpi.py:89\u001b[0m, in \u001b[0;36mMPIPool.__init__\u001b[0;34m(self, comm, use_dill)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomm\u001b[38;5;241m.\u001b[39mGet_size() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to create an MPI pool, but there \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwas only one MPI process available. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeed at least two.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Tried to create an MPI pool, but there was only one MPI process available. Need at least two."
     ]
    }
   ],
   "source": [
    "#No work\n",
    "FBratioArr = np.logspace(start=-2, stop=2, num=5, base=10.0)\n",
    "num_gals = 100\n",
    "g_true= [-0.03, -0.01, 0, 0.01, 0.03]\n",
    "seed = [1, 2, 3, 4, 5]\n",
    "version = 0\n",
    "first = False\n",
    "SbyN = 20\n",
    "data=[]\n",
    "\n",
    "for n in range(5):\n",
    "    element = (num_gals, FBratioArr[n], g_true[n], seed[n], version, first, SbyN)\n",
    "    data.append(element)\n",
    "    \n",
    "pool = MPIPool()\n",
    "if not pool.is_master():\n",
    "    pool.wait()\n",
    "    sys.exit(0)\n",
    "pool.map(analyze,data)\n",
    "pool.close()\n",
    "\n",
    "print(pool)\n",
    "#values = list(map(analyze, data))\n",
    "#print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d0519",
   "metadata": {},
   "outputs": [],
   "source": [
    "FBratioArr = np.logspace(start=-2, stop=2, num=5, base=10.0)\n",
    "num_gals = 100\n",
    "g_true= [-0.03, -0.01, 0, 0.01, 0.03]\n",
    "seed = [1, 2, 3, 4, 5]\n",
    "#seed = np.linspace(start=1, stop=len(g_true), num=len(g_true))\n",
    "\n",
    "shear_measurementsSB = []\n",
    "shear_errorsSB = []\n",
    "\n",
    "shear_measurementsB = []\n",
    "shear_errorsB = []\n",
    "\n",
    "for n in range(len(FBratioArr)):\n",
    "    analysis_BandS = analyze(num_gals, FBratioArr[n], g_true, seed, version=0, SbyN=10)\n",
    "    print(\"s2nArrBandS=\", analysis_BandS[3])\n",
    "    \n",
    "    shear_measurementsSB.append(analysis_BandS[1])\n",
    "    shear_errorsSB.append(analysis_BandS[2])\n",
    "    \n",
    "    analysis_Bonly = analyze(num_gals, FBratioArr[n], g_true, seed, version=1, SbyN=10)\n",
    "    print(\"FBBratioArr[n] =\", FBratioArr[n])\n",
    "    print(\"s2nArrBonly=\", analysis_Bonly[3])\n",
    "    \n",
    "    shear_measurementsB.append(analysis_Bonly[1])\n",
    "    shear_errorsB.append(analysis_Bonly[2])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd57ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shear_measurementsSB, \"\\n\")\n",
    "print(shear_errorsSB, \"\\n\")\n",
    "print(shear_measurementsB, \"\\n\")\n",
    "print(shear_errorsB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99ef034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#popt, pcov = scipy.optimize.curve_fit(biasFunc, shear_true[0], shear[0], sigma = shear_error[0])\n",
    "\n",
    "x = np.linspace(-.03*1.5, .03*1.5, len(FBratioArr))\n",
    "\n",
    "biasListSB = []\n",
    "errorListSB = []\n",
    "biasListB = []\n",
    "errorListB = []\n",
    "\n",
    "for i in range(len(g_true)):\n",
    "    print(shear_measurementsSB[i], \"\\n\")\n",
    "    \n",
    "print(\"shape =\", np.shape(g_true[0]))\n",
    "\n",
    "for n in range(len(g_true)):    \n",
    "\n",
    "    print(\"g_true[n] =\", g_true[n])\n",
    "    poptSB, pcovSB = scipy.optimize.curve_fit(biasFunc, g_true, shear_measurementsSB[n], sigma = shear_errorsSB[n])\n",
    "    print(\"shear_measurementsSB[n] = \",shear_measurementsSB[n], \"\\n\")\n",
    "    print(\"shear_errorsSB[n] = \",shear_errorsSB[n], \"\\n\")\n",
    "    print(\"poptSB = \",poptSB)\n",
    "    print(\"pcovSB =\", pcovSB, \"\\n\")\n",
    "    poptB, pcovB = scipy.optimize.curve_fit(biasFunc, g_true, shear_measurementsB[n], sigma = shear_errorsB[n])\n",
    "    print(\"shear_measurementsB[n] = \",shear_measurementsB[n], \"\\n\")\n",
    "    print(\"shear_errorsB[n] = \",shear_errorsB[n], \"\\n\")\n",
    "    print(\"poptB = \",poptB)\n",
    "    print(\"pcovB =\", pcovB, \"\\n\", \"\\n\")\n",
    "    \n",
    "    biasListSB.append(poptSB)\n",
    "    biasListB.append(poptB)\n",
    "    \n",
    "    errorListSB.append(pcovSB)\n",
    "    errorListB.append(pcovB)\n",
    "    \n",
    "    del poptSB, pcovSB, poptB, pcovB\n",
    "\n",
    "\n",
    "print(\"biasListSB =\", biasListSB, \"\\n\")\n",
    "print(\"errorListSB =\", errorListSB, \"\\n\")\n",
    "print(\"biasListB =\", biasListB, \"\\n\")\n",
    "print(\"errorListB =\", errorListB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669cd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "mListSB=[]\n",
    "cListSB=[]\n",
    "mListB=[]\n",
    "cListB=[]\n",
    "mErrSB=[]\n",
    "cErrSB=[]\n",
    "mErrB=[]\n",
    "cErrB=[]\n",
    "\n",
    "for n in range(len(biasListSB)):\n",
    "    mListSB.append(biasListSB[n][0])\n",
    "    mListB.append(biasListB[n][0])\n",
    "    cListSB.append(biasListSB[n][1])\n",
    "    cListB.append(biasListB[n][1])\n",
    "    mErrSB.append(np.sqrt(np.diag(errorListSB[n])[0]))\n",
    "    cErrSB.append(np.sqrt(np.diag(errorListSB[n])[1]))\n",
    "    mErrB.append(np.sqrt(np.diag(errorListB[n])[0]))\n",
    "    cErrB.append(np.sqrt(np.diag(errorListB[n])[1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab76da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (p1, p2) = plt.subplots(2, figsize=(15,20))\n",
    "\n",
    "print(biasListSB)\n",
    "print(biasListB)\n",
    "\n",
    "plot1 = p1.errorbar(np.array(FBratioArr)*1.1, mListSB, mErrSB, fmt='o', label='Background + Source')\n",
    "p1.errorbar(FBratioArr, mListB, mErrB, fmt='o', label='Background only')\n",
    "p1.set_title(\"Multiplicative Bias Plot\")\n",
    "p1.axhline(0, color=\"purple\")\n",
    "p1.set_xlabel(r'$\\frac{F}{B}$', fontsize=16)\n",
    "p1.set_ylabel(r'$m$', fontsize=16)\n",
    "p1.set_xscale(\"log\")\n",
    "p1.legend()\n",
    "\n",
    "plot2 = p2.errorbar(np.array(FBratioArr)*1.1, cListSB, cErrSB, fmt='o', label='Background + Source')\n",
    "p2.errorbar(FBratioArr, cListB, cErrB, fmt = 'o', label ='Background only')\n",
    "p2.axhline(0, color=\"purple\")\n",
    "p2.set_xlabel(r'$\\frac{F}{B}$', fontsize=16)\n",
    "p2.set_ylabel(r'$c$', fontsize=16)\n",
    "p2.set_xscale(\"log\")\n",
    "p2.set_title(\"Additive Bias Plot\")\n",
    "p2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a262b47c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
